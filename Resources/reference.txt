Gandalf by Lakera: https://gandalf.lakera.ai/gandalf
Immersive Labs: https://prompting.ai.immersivelabs.com/
Prompt Airlines by Wiz: https://promptairlines.com/
Damn Vulnerable LLM Agent: https://github.com/WithSecureLabs/damn-vulnerable-llm-agent

Prompt injection examples:

https://github.com/mik0w/pallms
https://github.com/Cranot/chatbot-injections-exploits
https://github.com/TakSec/Prompt-Injection-Everywhere
https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-adversarial.md
https://gist.github.com/deadbits/e93a90aa36c9aa7b5ce1179597a6fe3d

Hands-On practice on web chatbots:

https://portswigger.net/web-security/llm-attacks


AI for hacking:

Amazon PartyRock: https://partyrock.aws/home
Ollama: https://ollama.com/
Llama3 on Ollama setup guide: https://github.com/ollama/ollama
GPT4All: https://www.nomic.ai/gpt4all
"Uncensored" models: https://erichartford.com/uncensored-models and https://ollama.com/library/llama2-uncensored and https://ollama.com/gdisney/mistral-uncensored
https://github.com/GreyDGL/PentestGPT
https://github.com/ipa-lab/hackingBuddyGPT
Certifications:

https://secops.group/our-services/ai-ml-pentest/
https://learn.deeplearning.ai/courses/red-teaming-llm-applications/lesson/t1tp1/introduction?courseName=red-teaming-llm-applications
https://academy.hackthebox.com/path/preview/ai-red-teamer
https://aws.amazon.com/certification/certified-ai-practitioner/
Further reading:

https://lakera-marketing-public.s3.eu-west-1.amazonaws.com/Lakera%2BAI%2B-%2BReal%2BWorld%2BLLM%2BExploits%2B(Jan%2B2024)-min.pdf
https://wiki.offsecml.com/Welcome+to+the+Offensive+ML+Playbook
https://platform.dreadnode.io/
https://www.blazeinfosec.com/post/llm-pentest-agent-hacking/
https://learnprompting.org/docs/prompt_hacking/injection
https://llmsecurity.net/
https://genai.owasp.org/
https://aivillage.org/large%20language%20models/threat-modeling-llm/
https://github.com/ScottLogic/prompt-injection
https://github.com/greshake/llm-security
https://github.com/Hannibal046/Awesome-LLM
https://github.com/ottosulin/awesome-ai-security
https://atlas.mitre.org/matrices/ATLAS/
https://github.com/EasyJailbreak/EasyJailbreak
https://www.arthur.ai/blog/from-jailbreaks-to-gibberish-understanding-the-different-types-of-prompt-injections
